{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SveuÄiliÅ¡te u Zagrebu  \n",
    "Fakultet elektrotehnike i raÄunarstva  \n",
    "  \n",
    "## Strojno uÄenje 2019/2020  \n",
    "http://www.fer.unizg.hr/predmet/su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "### Laboratorijska vjeÅ¾ba 5: ProbabilistiÄki grafiÄki modeli, naivni Bayes, grupiranje i vrednovanje klasifikatora\n",
    "\n",
    "*Verzija: 1.5  \n",
    "Zadnji put aÅ¾urirano: 27. rujna 2019.*\n",
    "\n",
    "(c) 2015-2019 Jan Å najder, Domagoj AlagiÄ‡  \n",
    "\n",
    "Objavljeno: **30. rujna 2019.**  \n",
    "Rok za predaju: **20. sijeÄnja 2020. u 07:00h**\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upute\n",
    "\n",
    "Peta laboratorijska vjeÅ¾ba sastoji se od tri zadatka. U nastavku slijedite upute navedene u Ä‡elijama s tekstom. RjeÅ¡avanje vjeÅ¾be svodi se na **dopunjavanje ove biljeÅ¾nice**: umetanja Ä‡elije ili viÅ¡e njih **ispod** teksta zadatka, pisanja odgovarajuÄ‡eg kÃ´da te evaluiranja Ä‡elija. \n",
    "\n",
    "Osigurajte da u potpunosti **razumijete** kÃ´d koji ste napisali. Kod predaje vjeÅ¾be, morate biti u stanju na zahtjev asistenta (ili demonstratora) preinaÄiti i ponovno evaluirati VaÅ¡ kÃ´d. Nadalje, morate razumjeti teorijske osnove onoga Å¡to radite, u okvirima onoga Å¡to smo obradili na predavanju. Ispod nekih zadataka moÅ¾ete naÄ‡i i pitanja koja sluÅ¾e kao smjernice za bolje razumijevanje gradiva (**nemojte pisati** odgovore na pitanja u biljeÅ¾nicu). Stoga se nemojte ograniÄiti samo na to da rijeÅ¡ite zadatak, nego slobodno eksperimentirajte. To upravo i jest svrha ovih vjeÅ¾bi.\n",
    "\n",
    "VjeÅ¾be trebate raditi **samostalno**. MoÅ¾ete se konzultirati s drugima o naÄelnom naÄinu rjeÅ¡avanja, ali u konaÄnici morate sami odraditi vjeÅ¾bu. U protivnome vjeÅ¾ba nema smisla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# UÄitaj osnovne biblioteke...\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import codecs\n",
    "import mlutils\n",
    "import matplotlib.pyplot as plt\n",
    "import pgmpy as pgm\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ProbabilistiÄki grafiÄki modeli -- Bayesove mreÅ¾e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovaj zadatak bavit Ä‡e se Bayesovim mreÅ¾ama, jednim od poznatijih probabilistiÄkih grafiÄkih modela (*probabilistic graphical models*; PGM). Za lakÅ¡e eksperimentiranje koristit Ä‡emo programski paket [`pgmpy`](https://github.com/pgmpy/pgmpy). Molimo Vas da provjerite imate li ovaj paket te da ga instalirate ako ga nemate. Upute se nalaze na gornjoj poveznici. Za korisnike Anaconde, najlakÅ¡e je upisati `conda install -c ankurankan pgmpy` unutar Anaconda Prompta (i ponovno pokrenuti Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)  \n",
    "Prvo Ä‡emo pogledati udÅ¾beniÄki primjer s prskalicom. U ovom primjeru razmatramo Bayesovu mreÅ¾u koja modelira zavisnosti izmeÄ‘u oblaÄnosti (sluÄajna varijabla $C$), kiÅ¡e ($R$), prskalice ($S$) i mokre trave ($W$). U ovom primjeru takoÄ‘er pretpostavljamo da veÄ‡ imamo parametre vjerojatnosnih distribucija svih Ävorova. Ova mreÅ¾a prikazana je na sljedeÄ‡oj slici:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![This](http://www.fer.unizg.hr/_download/repository/bayes-net-sprinkler.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KoristeÄ‡i paket `pgmpy`, konstruirajte Bayesovu mreÅ¾u iz gornjeg primjera. Zatim, koristeÄ‡i **egzaktno** zakljuÄivanje, postavite sljedeÄ‡e posteriorne upite: $P(w=1)$, $P(s=1|w=1)$, $P(r=1|w=1)$, $P(c=1|s=1, r=1)$ i $P(c=1)$. Provedite zakljuÄivanje na papiru i uvjerite se da ste ispravno konstruirali mreÅ¾u. PomoÄ‡i Ä‡e vam sluÅ¾bena dokumentacija te primjeri koriÅ¡tenja (npr. [ovaj](https://github.com/pgmpy/pgmpy/blob/dev/examples/Monty%20Hall%20Problem.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD\n",
    "from pgmpy.inference import VariableElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<TabularCPD representing P(C:2) at 0x7f0b2e507710>,\n",
       " <TabularCPD representing P(S:2 | C:2) at 0x7f0b2e5077b8>,\n",
       " <TabularCPD representing P(R:2 | C:2) at 0x7f0b2e5077f0>,\n",
       " <TabularCPD representing P(W:2 | S:2, R:2) at 0x7f0b2e5078d0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the network structure\n",
    "model = BayesianModel([('C', 'S'), ('C', 'R'), ('S', 'W'), ('R', 'W')])\n",
    "\n",
    "# Defining the CPDs:\n",
    "cpd_c = TabularCPD('C', 2, [[0.5], [0.5]])\n",
    "cpd_s = TabularCPD('S', 2, [[0.5, 0.9], \n",
    "                            [0.5, 0.1]],\n",
    "                  evidence=['C'], evidence_card=[2])\n",
    "cpd_r = TabularCPD('R', 2, [[0.8, 0.2], \n",
    "                            [0.2, 0.8]],\n",
    "                  evidence=['C'], evidence_card=[2])\n",
    "\n",
    "cpd_w = TabularCPD('W', 2, [[1.0, 0.1, 0.1, 0.01], \n",
    "                            [0.0, 0.9, 0.9, 0.99]],\n",
    "                  evidence=['S', 'R'], evidence_card=[2, 2])\n",
    "\n",
    "# Associating the CPDs with the network structure.\n",
    "model.add_cpds(cpd_c,cpd_s,cpd_r,cpd_w)\n",
    "\n",
    "# Some other methods\n",
    "model.get_cpds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check_model check for the model structure and the associated CPD and \n",
    "# returns True if everything is correct otherwise throws an exception\n",
    "model.check_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1636.27it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 351.63it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1021.63it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 382.01it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 1002.34it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 560.10it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 849.74it/s]\n",
      "Eliminating: W: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 686.02it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1446.64it/s]\n",
      "Eliminating: R: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 216.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğ‘ƒ(ğ‘¤=1)\n",
      "+------+----------+\n",
      "| W    |   phi(W) |\n",
      "+======+==========+\n",
      "| W(0) |   0.3529 |\n",
      "+------+----------+\n",
      "| W(1) |   0.6471 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(ğ‘ =1|ğ‘¤=1)\n",
      "+------+----------+\n",
      "| S    |   phi(S) |\n",
      "+======+==========+\n",
      "| S(0) |   0.5702 |\n",
      "+------+----------+\n",
      "| S(1) |   0.4298 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(ğ‘Ÿ=1|ğ‘¤=1)\n",
      "+------+----------+\n",
      "| R    |   phi(R) |\n",
      "+======+==========+\n",
      "| R(0) |   0.2921 |\n",
      "+------+----------+\n",
      "| R(1) |   0.7079 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(ğ‘=1|ğ‘ =1,ğ‘Ÿ=1)\n",
      "+------+----------+\n",
      "| C    |   phi(C) |\n",
      "+======+==========+\n",
      "| C(0) |   0.5556 |\n",
      "+------+----------+\n",
      "| C(1) |   0.4444 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(ğ‘=1)\n",
      "+------+----------+\n",
      "| C    |   phi(C) |\n",
      "+======+==========+\n",
      "| C(0) |   0.5000 |\n",
      "+------+----------+\n",
      "| C(1) |   0.5000 |\n",
      "+------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "infer = VariableElimination(model)\n",
    "# ğ‘ƒ(ğ‘¤=1)\n",
    "posterior_w = infer.query(['W'])\n",
    "print(\"\\nğ‘ƒ(ğ‘¤=1)\")\n",
    "print(posterior_w)\n",
    "\n",
    "# ğ‘ƒ(ğ‘ =1|ğ‘¤=1)\n",
    "posterior_s = infer.query(['S'], evidence={'W': 1})\n",
    "print(\"\\nğ‘ƒ(ğ‘ =1|ğ‘¤=1)\")\n",
    "print(posterior_s)\n",
    "\n",
    "# ğ‘ƒ(ğ‘Ÿ=1|ğ‘¤=1)\n",
    "posterior_r = infer.query(['R'], evidence={'W': 1})\n",
    "print(\"\\nğ‘ƒ(ğ‘Ÿ=1|ğ‘¤=1)\")\n",
    "print(posterior_r)\n",
    "\n",
    "\n",
    "# ğ‘ƒ(ğ‘=1|ğ‘ =1,ğ‘Ÿ=1)\n",
    "posterior_c = infer.query(['C'], evidence={'S': 1, 'R': 1})\n",
    "print(\"\\nğ‘ƒ(ğ‘=1|ğ‘ =1,ğ‘Ÿ=1)\")\n",
    "print(posterior_c)\n",
    "\n",
    "# ğ‘ƒ(ğ‘=1)\n",
    "posterior_c = infer.query(['C'])\n",
    "print(\"\\nğ‘ƒ(ğ‘=1)\")\n",
    "print(posterior_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koju zajedniÄku vjerojatnosnu razdiobu ova mreÅ¾a modelira? Kako tu informaciju oÄitati iz mreÅ¾e?  \n",
    "**Q:** U zadatku koristimo egzaktno zakljuÄivanje. Kako ono radi?  \n",
    "**Q:** Koja je razlika izmeÄ‘u posteriornog upita i MAP-upita?  \n",
    "**Q:** ZaÅ¡to je vjerojatnost $P(c=1)$ drugaÄija od $P(c=1|s=1,r=1)$ ako znamo da Ävorovi $S$ i $R$ nisu roditelji Ävora $C$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)  \n",
    "**Efekt objaÅ¡njavanja** (engl. *explaining away*) zanimljiv je fenomen u kojem se dogaÄ‘a da se dvije varijable \"natjeÄu\" za objaÅ¡njavanje treÄ‡e. Ovaj fenomen moÅ¾e se primijetiti na gornjoj mreÅ¾i. U tom se sluÄaju varijable prskalice ($S$) i kiÅ¡e ($R$) \"natjeÄu\" za objaÅ¡njavanje mokre trave ($W$). VaÅ¡ zadatak je pokazati da se fenomen zaista dogaÄ‘a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1908.24it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 499.70it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 1141.31it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 344.13it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 734.10it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 165.94it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğ‘ƒ(s=1)\n",
      "+------+----------+\n",
      "| S    |   phi(S) |\n",
      "+======+==========+\n",
      "| S(0) |   0.7000 |\n",
      "+------+----------+\n",
      "| S(1) |   0.3000 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(r=1)\n",
      "+------+----------+\n",
      "| R    |   phi(R) |\n",
      "+======+==========+\n",
      "| R(0) |   0.5000 |\n",
      "+------+----------+\n",
      "| R(1) |   0.5000 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(s=1|w=1)\n",
      "+------+----------+\n",
      "| S    |   phi(S) |\n",
      "+======+==========+\n",
      "| S(0) |   0.5702 |\n",
      "+------+----------+\n",
      "| S(1) |   0.4298 |\n",
      "+------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 422.03it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 205.12it/s]\n",
      "Finding Elimination Order: : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 506.44it/s]\n",
      "Eliminating: C: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 186.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğ‘ƒ(r=1|w=1)\n",
      "+------+----------+\n",
      "| R    |   phi(R) |\n",
      "+======+==========+\n",
      "| R(0) |   0.2921 |\n",
      "+------+----------+\n",
      "| R(1) |   0.7079 |\n",
      "+------+----------+\n",
      "\n",
      "ğ‘ƒ(s=1|r=1,w=1)\n",
      "+------+----------+\n",
      "| S    |   phi(S) |\n",
      "+======+==========+\n",
      "| S(0) |   0.8055 |\n",
      "+------+----------+\n",
      "| S(1) |   0.1945 |\n",
      "+------+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "posterior_s = infer.query(['S'])\n",
    "print(\"\\nğ‘ƒ(s=1)\")\n",
    "print(posterior_s)\n",
    "\n",
    "posterior_r = infer.query(['R'])\n",
    "print(\"\\nğ‘ƒ(r=1)\")\n",
    "print(posterior_r)\n",
    "\n",
    "\n",
    "posterior_s = infer.query(['S'], evidence={'W': 1})\n",
    "print(\"\\nğ‘ƒ(s=1|w=1)\")\n",
    "print(posterior_s)\n",
    "\n",
    "posterior_r = infer.query(['R'], evidence={'W': 1})\n",
    "print(\"\\nğ‘ƒ(r=1|w=1)\")\n",
    "print(posterior_r)\n",
    "\n",
    "posterior_s = infer.query(['S'], evidence={'R': 1,'W': 1})\n",
    "print(\"\\nğ‘ƒ(s=1|r=1,w=1)\")\n",
    "print(posterior_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako biste svojim rijeÄima opisali ovaj fenomen, koristeÄ‡i se ovim primjerom?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)  \n",
    "KoristeÄ‡i [`BayesianModel.is_active_trail`](http://pgmpy.org/models.html#pgmpy.models.BayesianModel.BayesianModel.is_active_trail) provjerite jesu li varijable oblaÄnosti ($C$) i mokre trave ($W$) uvjetno nezavisne. Å to mora vrijediti kako bi te dvije varijable bile uvjetno nezavisne? Provjerite koriÅ¡tenjem iste funkcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# VaÅ¡ kÃ´d ovdje\n",
    "print(model.is_active_trail('C','W'))\n",
    "\n",
    "print(model.is_active_trail('C','W', observed='S'))\n",
    "\n",
    "print(model.is_active_trail('C','W', observed='R'))\n",
    "\n",
    "print(model.is_active_trail('C','W',observed=['S', 'R']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako moÅ¾emo na temelju grafa saznati koje dvije varijable su, uz neka opaÅ¾anja, uvjetno nezavisne?  \n",
    "**Q:** ZaÅ¡to bismo uopÄ‡e htjeli znati koje su varijable u mreÅ¾i uvjetno nezavisne?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vrednovanje modela (klasifikatora)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako bismo se uvjerili koliko naÅ¡ nauÄeni model zapravo dobro radi, nuÅ¾no je provesti evaluaciju modela. Ovaj korak od presudne je vaÅ¾nosti u svim primjenama strojnog uÄenja, pa je stoga bitno znati provesti evaluaciju na ispravan naÄin.\n",
    "\n",
    "Vrednovat Ä‡emo modele na stvarnom skupu podataka [*SMS Spam Collection*](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) [1], koji se sastoji od 5,574 SMS-poruka klasificiranih u dvije klase: spam (oznaka: *spam*) i ne-spam (oznaka: *ham*). Ako veÄ‡ niste, preuzmite skup podataka s poveznice ili sa stranice kolegija i stavite ga u radni direktorij (otpakirajte arhivu i preimenujte datoteku u `spam.csv` po potrebi). SljedeÄ‡i komad kÃ´da uÄitava skup podataka i dijeli ga na podskupove za uÄenje i testiranje.\n",
    "\n",
    "[1] *Almeida, T.A., GÃƒmez Hidalgo, J.M., Yamakami, A. Contributions to the Study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11), Mountain View, CA, USA, 2011.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "spam_X, spam_y = mlutils.load_SMS_dataset('./spam.csv')\n",
    "\n",
    "spam_X_train, spam_X_test, spam_y_train, spam_y_test = \\\n",
    "    train_test_split(spam_X, spam_y, train_size=0.7, test_size=0.3, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)  \n",
    "Prije nego Å¡to krenemo u vrednovanje modela za klasifikaciju spama, upoznat Ä‡ete se s jednostavnijom apstrakcijom cjelokupnog procesa uÄenja modela u biblioteci `scikit-learn`. Ovo je korisno zato Å¡to se uÄenje modela Äesto sastoji od mnoÅ¡tva koraka prije sÃ¢mog pozivanja magiÄne funkcije `fit`: ekstrakcije podataka, ekstrakcije znaÄajki, standardizacije, skaliranja, nadopunjavanjem nedostajuÄ‡ih vrijednosti i sliÄno. \n",
    "\n",
    "U \"standardnom pristupu\", ovo se svodi na pozamaÅ¡an broj linija kÃ´da u kojoj konstantno proslijeÄ‘ujemo podatke iz jednog koraka u sljedeÄ‡i, tvoreÄ‡i pritom cjevovod izvoÄ‘enja. Osim nepreglednosti, ovakav pristup je Äesto i sklon pogreÅ¡kama, s obzirom na to da je dosta jednostavno proslijediti pogreÅ¡an skup podataka i ne dobiti pogreÅ¡ku pri izvoÄ‘enju kÃ´da. Stoga je u biblioteci `scikit-learn` uveden razred [`pipeline.Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Kroz ovaj razred, svi potrebni koraci uÄenja mogu se apstrahirati iza jednog cjevovoda, koji je opet zapravo model s `fit` i `predict` funkcijama.\n",
    "\n",
    "U ovom zadatku Ä‡ete napraviti samo jednostavni cjevovod modela za klasifikaciju teksta, koji se sastoji od pretvorbe teksta u vektorsku reprezentaciju vreÄ‡e rijeÄi s TF-IDF-teÅ¾inama, redukcije dimenzionalnosti pomoÄ‡u krnje dekompozicije singularnih vrijednosti, normalizacije, te konaÄno logistiÄke regresije.\n",
    "\n",
    "**NB:** Nije sasvim nuÅ¾no znati kako rade ovi razredi pomoÄ‡u kojih dolazimo do konaÄnih znaÄajki, ali preporuÄamo da ih prouÄite ako vas zanima (posebice ako vas zanima obrada prirodnog jezika)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvo, prilaÅ¾emo kÃ´d koji to radi \"standardnim pristupom\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659294680215182\n",
      "['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "spam_X_feat_train = vectorizer.fit_transform(spam_X_train)\n",
    "\n",
    "# Smanjenje dimenzionalnosti\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "spam_X_feat_train = reducer.fit_transform(spam_X_feat_train)\n",
    "\n",
    "# Normaliziranje\n",
    "normalizer = Normalizer()\n",
    "spam_X_feat_train = normalizer.fit_transform(spam_X_feat_train)\n",
    "\n",
    "# NB\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "clf.fit(spam_X_feat_train, spam_y_train)\n",
    "\n",
    "# I sada ponovno sve ovo za testne podatke.\n",
    "spam_X_feat_test = vectorizer.transform(spam_X_test)\n",
    "spam_X_feat_test = reducer.transform(spam_X_feat_test)\n",
    "spam_X_feat_test = normalizer.transform(spam_X_feat_test)\n",
    "\n",
    "print(accuracy_score(spam_y_test, clf.predict(spam_X_feat_test)))\n",
    "\n",
    "x_test = [\"You were selected for a green card, apply here for only 50 USD!!!\",\n",
    "         \"Hey, what are you doing later? Want to grab a cup of coffee?\"]\n",
    "x_test = vectorizer.transform(x_test)\n",
    "x_test = reducer.transform(x_test)\n",
    "x_test = normalizer.transform(x_test)\n",
    "print(clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VaÅ¡ zadatak izvesti je dani kÃ´d koriÅ¡tenjem cjevovoda. ProuÄite razred [`pipeline.Pipeline`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "**NB** Ne treba vam viÅ¡e od svega nekoliko naredbi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9659294680215182\n",
      "['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# VaÅ¡ kÃ´d ovdje\n",
    "# spam_X_train, spam_X_test, spam_y_train, spam_y_test\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "normalizer = Normalizer()\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "\n",
    "pipeline_clf.fit(spam_X_train, spam_y_train)\n",
    "\n",
    "print(accuracy_score(spam_y_test, pipeline_clf.predict(spam_X_test)))\n",
    "\n",
    "x_test = [\"You were selected for a green card, apply here for only 50 USD!!!\",\n",
    "         \"Hey, what are you doing later? Want to grab a cup of coffee?\"]\n",
    "\n",
    "print(pipeline_clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)  \n",
    "U proÅ¡lom smo podzadatku ispisali toÄnost naÅ¡eg modela. Ako Å¾elimo vidjeti koliko je naÅ¡ model dobar po ostalim metrikama, moÅ¾emo iskoristiti bilo koju funkciju iz paketa [`metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). PosluÅ¾ite se funkcijom [`metrics.classification_report`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report), koja ispisuje vrijednosti najÄeÅ¡Ä‡ih metrika. (Obavezno koristite naredbu `print` kako ne biste izgubili format izlaza funkcije.) IspiÅ¡ite ponovno toÄnost za usporedbu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1439\n",
      "        spam       0.97      0.78      0.86       234\n",
      "\n",
      "    accuracy                           0.97      1673\n",
      "   macro avg       0.97      0.89      0.92      1673\n",
      "weighted avg       0.97      0.97      0.96      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# VaÅ¡ kÃ´d ovdje\n",
    "print(classification_report(spam_y_test, pipeline_clf.predict(spam_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potreba za drugim metrikama osim toÄnosti moÅ¾e se vidjeti pri koriÅ¡tenju nekih osnovnih modela (engl. *baselines*). MoÅ¾da najjednostavniji model takvog tipa je model koji svrstava sve primjere u veÄ‡insku klasu (engl. *most frequent class*; MFC) ili oznaÄuje testne primjere nasumiÄno (engl. *random*). ProuÄite razred [`dummy.DummyClassifier`](http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) i pomoÄ‡u njega stvorite spomenute osnovne klasifikatore. Opet Ä‡ete trebati iskoristiti cjevovod kako biste doÅ¡li do vektorskog oblika ulaznih primjera, makar ovi osnovni klasifikatori koriste samo oznake pri predikciji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST FREQUENT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.86      1.00      0.92      1439\n",
      "        spam       0.00      0.00      0.00       234\n",
      "\n",
      "    accuracy                           0.86      1673\n",
      "   macro avg       0.43      0.50      0.46      1673\n",
      "weighted avg       0.74      0.86      0.80      1673\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mislav/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# VaÅ¡ kÃ´d ovdje\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "normalizer = Normalizer()\n",
    "clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "pipeline_clf.fit(spam_X_train, spam_y_train)\n",
    "print(\"MOST FREQUENT\")\n",
    "print(classification_report(spam_y_test, pipeline_clf.predict(spam_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.50      0.63      1439\n",
      "        spam       0.15      0.53      0.23       234\n",
      "\n",
      "    accuracy                           0.50      1673\n",
      "   macro avg       0.51      0.52      0.43      1673\n",
      "weighted avg       0.77      0.50      0.58      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "normalizer = Normalizer()\n",
    "clf = DummyClassifier(strategy=\"uniform\",random_state=69)\n",
    "\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "pipeline_clf.fit(spam_X_train, spam_y_train)\n",
    "print(\"RANDOM\")\n",
    "print(classification_report(spam_y_test, pipeline_clf.predict(spam_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Na temelju ovog primjera objasnite zaÅ¡to toÄnost nije uvijek prikladna metrika.  \n",
    "**Q:** ZaÅ¡to koristimo F1-mjeru?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)  \n",
    "MeÄ‘utim, provjera za kakvom smo posegli u proÅ¡lom podzadatku nije robusna. Stoga se u strojnom uÄenju obiÄno koristi k-struka unakrsna provjera. ProuÄite razred [`model_selection.KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) i funkciju [`model_selection.cross_val_score`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) te izraÄunajte procjenu pogreÅ¡ke na cijelom skupu podataka koristeÄ‡i peterostruku unakrsnu provjeru. \n",
    "\n",
    "**NB:** VaÅ¡ model je sada cjevovod koji sadrÅ¾i Äitavo pretprocesiranje. TakoÄ‘er, u nastavku Ä‡emo se ograniÄiti na toÄnost, ali ovi postupci vrijede za sve metrike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "TRAIN: [1115 1116 1117 ... 5571 5572 5573] TEST: [   0    1    2 ... 1112 1113 1114]\n",
      "TRAIN: [   0    1    2 ... 5571 5572 5573] TEST: [1115 1116 1117 ... 2227 2228 2229]\n",
      "TRAIN: [   0    1    2 ... 5571 5572 5573] TEST: [2230 2231 2232 ... 3342 3343 3344]\n",
      "TRAIN: [   0    1    2 ... 5571 5572 5573] TEST: [3345 3346 3347 ... 4457 4458 4459]\n",
      "TRAIN: [   0    1    2 ... 4457 4458 4459] TEST: [4460 4461 4462 ... 5571 5572 5573]\n",
      "[0.9766816143497757, 0.9766816143497757, 0.967713004484305, 0.9704035874439462, 0.9757630161579892]\n",
      "[0.97670251 0.97670251 0.96678636 0.97127469 0.97666068]\n"
     ]
    }
   ],
   "source": [
    "# VaÅ¡ kÃ´d ovdje\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(spam_X)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "normalizer = Normalizer()\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "\n",
    "pipeline_clf.fit(spam_X_train, spam_y_train)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "accuracy = []\n",
    "\n",
    "for train_index, test_index in kf.split(spam_X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = spam_X[train_index], spam_X[test_index]\n",
    "    y_train, y_test = spam_y[train_index], spam_y[test_index]\n",
    "    \n",
    "    pipeline_clf.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy.append(accuracy_score(y_test,pipeline_clf.predict(X_test)))\n",
    "    \n",
    "print(accuracy)\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "\n",
    "print(cross_val_score(pipeline_clf,spam_X,spam_y,cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** ZaÅ¡to \"obiÄna\" unakrsna provjera nije dovoljno robusna?  \n",
    "**Q:** Å to je to stratificirana k-struka unakrsna provjera? ZaÅ¡to ju Äesto koristimo?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)  \n",
    "\n",
    "Gornja procjena pogreÅ¡ke je u redu ako veÄ‡ imamo model (bez ili s fiksiranim hiperparametrima). MeÄ‘utim, mi Å¾elimo koristiti model koji ima optimalne vrijednosti hiperparametara te ih je stoga potrebno optimirati koriÅ¡tenjem pretraÅ¾ivanja po reÅ¡etci (engl. *grid search*). OÄekivano, biblioteka `scikit-learn` veÄ‡ ima ovu funkcionalnost u razredu [`model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Jedina razlika vaÅ¡e implementacije iz proÅ¡lih vjeÅ¾bi (npr. kod SVM-a) i ove jest ta da ova koristi k-struku unakrsnu provjeru.\n",
    "\n",
    "Prije optimizacije vrijednosti hiperparametara, oÄigledno moramo definirati i samu reÅ¡etku vrijednosti hiperparametara. ProuÄite kako se definira ista kroz rjeÄnik u [primjeru](http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py). \n",
    "\n",
    "ProuÄite spomenuti razred te pomoÄ‡u njega pronaÄ‘ite i ispiÅ¡ite najbolje vrijednosti hiperparametara cjevovoda iz podzadatka (a): `max_features` $\\in \\{500, 1000\\}$ i `n_components` $\\in \\{ 100, 200, 300 \\}$ koriÅ¡tenjem pretraÅ¾ivanja po reÅ¡etci na skupu za uÄenje ($k=3$, kako bi iÅ¡lo malo brÅ¾e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# VaÅ¡ kÃ´d ovdje\n",
    "max_features = [500, 1000]\n",
    "n_components = [100, 200, 300]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "normalizer = Normalizer()\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "\n",
    "parameters = {'vectoriser__max_features':(500, 1000), 'reducer__n_components':[100, 200, 300]}\n",
    "\n",
    "clf = GridSearchCV(pipeline_clf, parameters,cv=3)\n",
    "clf.fit(spam_X, spam_y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.976\n",
      "Best parameters set:\n",
      "\treducer__n_components: 300\n",
      "\tvectoriser__max_features: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koja se metrika optimira pri ovoj optimizaciji?  \n",
    "**Q:** Kako biste odredili broj preklopa $k$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e)  \n",
    "Ako Å¾elimo procijeniti pogreÅ¡ku, ali pritom i napraviti odabir modela, tada se okreÄ‡emo ugnijeÅ¾Ä‘enoj k-strukoj unakrsnoj provjeri (engl. *nested k-fold cross validation*). U ovom zadatku Ä‡ete ju sami implementirati.\n",
    "\n",
    "Implementirajte funkciju `nested_kfold_cv(clf, param_grid, X, y, k1, k2)` koja provodi ugnijeÅ¾Ä‘enu k-struku unakrsnu provjeru. Argument `clf` predstavlja vaÅ¡ klasifikator, `param_grid` rjeÄnik vrijednosti hiperparametara (isto kao i u podzadatku (d)), `X` i `y` oznaÄeni skup podataka, a `k1` i `k2` broj preklopa u vanjskoj, odnosno unutarnjoj petlji. PosluÅ¾ite se razredima [`model_selection.GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) i  [`model_selection.KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html).\n",
    "\n",
    "Funkcija vraÄ‡a listu pogreÅ¡aka kroz preklope vanjske petlje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_kfold_cv(clf, param_grid, X, y, k1=10, k2=3):\n",
    "    kf1 = KFold(n_splits=k1)\n",
    "    #kf1.get_n_splits(X)\n",
    "    \n",
    "    kf2 = KFold(n_splits=k2)\n",
    "    #kf2.get_n_splits(X)\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    for train_index, test_index in kf1.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        clf_grid = GridSearchCV(clf, parameters,cv=kf2)\n",
    "        clf_grid.fit(X_train,y_train)\n",
    "        \n",
    "        best_clf = clf_grid.best_estimator_\n",
    "        best_clf.fit(X_train, y_train)\n",
    "    \n",
    "        errors.append(1.0 - accuracy_score(y_test,best_clf.predict(X_test)))\n",
    "    \n",
    "    return errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2), max_features=500)\n",
    "reducer = TruncatedSVD(n_components=300, random_state=69)\n",
    "normalizer = Normalizer()\n",
    "clf = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "pipeline_clf = Pipeline([('vectoriser', vectorizer), ('reducer', reducer), ('normalizer', normalizer), ('clf', clf)])\n",
    "parameters = {'vectoriser__max_features':(500, 1000), 'reducer__n_components':[100, 200, 300]}\n",
    "\n",
    "accuracy = nested_kfold_cv(pipeline_clf,parameters, spam_X, spam_y, k1=5, k2=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako biste odabrali koji su hiperparametri generalno najbolji, a ne samo u svakoj pojedinaÄnoj unutarnjoj petlji?  \n",
    "**Q:** ÄŒemu u konaÄnici odgovara procjena generalizacijske pogreÅ¡ke?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f)  \n",
    "Scenarij koji nas najviÅ¡e zanima jest usporedba dvaju klasifikatora, odnosno, je li jedan od njih zaista bolji od drugog. Jedini naÄin kako to moÅ¾emo zaista potvrditi jest statistiÄkom testom, u naÅ¡em sluÄaju **uparenim t-testom**. Njime Ä‡emo se baviti u ovom zadatku.\n",
    "\n",
    "Radi brÅ¾eg izvoÄ‘enja, umjetno Ä‡emo generirati podatke koji odgovaraju pogreÅ¡kama kroz vanjske preklope dvaju klasifikatora (ono Å¡to bi vratila funkcija `nested_kfold_cv`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "C1_scores_5folds = np.random.normal(78, 4, 5)\n",
    "C2_scores_5folds = np.random.normal(81, 2, 5)\n",
    "\n",
    "C1_scores_10folds = np.random.normal(78, 4, 10)\n",
    "C2_scores_10folds = np.random.normal(81, 2, 10)\n",
    "\n",
    "C1_scores_50folds = np.random.normal(78, 4, 50)\n",
    "C2_scores_50folds = np.random.normal(81, 2, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iskoristite ugraÄ‘enu funkciju [`scipy.stats.ttest_rel`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_rel.html) za provedbu uparenog t-testa i provjerite koji od ova modela je bolji kada se koristi 5, 10 i 50 preklopa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ttest_rel(C1_scores_5folds,C2_scores_5folds))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(ttest_rel(C1_scores_10folds,C2_scores_10folds))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(ttest_rel(C1_scores_50folds,C2_scores_50folds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koju hipotezu $H_0$ i alternativnu hipotezu $H_1$ testiramo ovim testom?  \n",
    "**Q:** Koja pretpostavka na vjerojatnosnu razdiobu primjera je napravljena u gornjem testu? Je li ona opravdana?  \n",
    "**Q:** Koji je model u konaÄnici bolji i je li ta prednost znaÄajna uz $\\alpha = 0.05$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Grupiranje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U ovom zadatku Ä‡ete se upoznati s algoritmom k-sredina (engl. *k-means*), njegovim glavnim nedostatcima te pretpostavkama. TakoÄ‘er Ä‡ete isprobati i drugi algoritam grupiranja: model Gaussovih mjeÅ¡avina (engl. *Gaussian mixture model*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a)  \n",
    "Jedan od nedostataka algoritma k-sredina jest taj Å¡to unaprijed zahtjeva broj grupa ($K$) u koje Ä‡e grupirati podatke. Ta informacija nam Äesto nije dostupna (kao Å¡to nam nisu dostupne ni oznake primjera) te je stoga potrebno nekako izabrati najbolju vrijednost hiperparametra $K$. Jedan od naivnijih pristupa jest **metoda lakta/koljena** (engl. *elbow method*) koju Ä‡ete isprobati u ovom zadatku.\n",
    "\n",
    "U svojim rjeÅ¡enjima koristite ugraÄ‘enu implementaciju algoritma k-sredina, dostupnoj u razredu [`cluster.KMeans`](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html). \n",
    "\n",
    "**NB**: Kriterijska funkcija algoritma k-sredina joÅ¡ se i naziva **inercijom** (engl. *inertia*). Za nauÄeni model, vrijednost kriterijske funkcije $J$ dostupna je kroz razredni atribut `inertia_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "Xp, yp = make_blobs(n_samples=300, n_features=2, centers=[[0, 0], [3, 2.5], [0, 4]], \n",
    "                    cluster_std=[0.45, 0.3, 0.45], random_state=96)\n",
    "plt.scatter(Xp[:,0], Xp[:,1], c=yp, cmap=plt.get_cmap(\"cool\"), s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iskoristite skup podataka `Xp` dan gore. Isprobajte vrijednosti hiperparametra $K$ iz $[0,1,\\ldots,15]$. Ne trebate dirati nikakve hiperparametre modela osim $K$. Iscrtajte krivulju od $J$ u ovisnosti o broju grupa $K$. Metodom lakta/koljena odredite vrijednost hiperparametra $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaÅ¡ kÃ´d ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Koju biste vrijednost hiperparametra $K$ izabrali na temelju ovog grafa? ZaÅ¡to? Je li taj odabir optimalan? Kako to znate?    \n",
    "**Q:** Je li ova metoda robusna?  \n",
    "**Q:** MoÅ¾emo li izabrati onaj $K$ koji minimizira pogreÅ¡ku $J$? Objasnite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b)  \n",
    "Odabir vrijednosti hiperparametra $K$ moÅ¾e se obaviti na mnoÅ¡tvo naÄina. Pored metode lakta/koljena, moguÄ‡e je isto ostvariti i analizom siluete (engl. *silhouette analysis*). Za to smo pripremili funkciju `mlutils.plot_silhouette` koja za dani broj grupa i podatke iscrtava prosjeÄnu vrijednost koeficijenta siluete i vrijednost koeficijenta svakog primjera (kroz grupe). \n",
    "\n",
    "VaÅ¡ je zadatak isprobati razliÄite vrijednosti hiperparametra $K$, $K \\in \\{2, 3, 5\\}$ i na temelju dobivenih grafova odluÄiti se za optimalan $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaÅ¡ kÃ´d ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Kako biste se gledajuÄ‡i ove slike odluÄili za $K$?  \n",
    "**Q:** Koji su problemi ovog pristupa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c)  \n",
    "U ovom i sljedeÄ‡im podzadatcima fokusirat Ä‡emo se na temeljne pretpostavke algoritma k-sredina te Å¡to se dogaÄ‘a ako te pretpostavke nisu zadovoljene. Dodatno, isprobat Ä‡emo i grupiranje modelom Gaussovih mjeÅ¡avina (engl. *Gaussian Mixture Models*; GMM) koji ne nema neke od tih pretpostavki.\n",
    "\n",
    "Prvo, krenite od podataka `X1`, koji su generirani koriÅ¡tenjem funkcije [`datasets.make_blobs`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html), koja stvara grupe podataka pomoÄ‡u izotropskih Gaussovih distribucija."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X1, y1 = make_blobs(n_samples=1000, n_features=2, centers=[[0, 0], [1.3, 1.3]], cluster_std=[0.15, 0.5], random_state=96)\n",
    "plt.scatter(X1[:,0], X1[:,1], c=y1, cmap=plt.get_cmap(\"cool\"), s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NauÄite model k-sredina (idealno pretpostavljajuÄ‡i $K=2$) na gornjim podatcima i prikaÅ¾ite dobiveno grupiranje (prouÄite funkciju [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter), posebice argument `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaÅ¡ kÃ´d ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Å to se dogodilo? Koja je pretpostavka algoritma k-sredina ovdje naruÅ¡ena?  \n",
    "**Q:** Å to biste morali osigurati kako bi algoritam pronaÅ¡ao ispravne grupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d)\n",
    "\n",
    "Isprobajte algoritam k-sredina na podatcima generiranim koriÅ¡tenjem funkcije [`datasets.make_circles`](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html), koja stvara dvije grupe podataka tako da je jedna unutar druge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "X2, y2 = make_circles(n_samples=1000, noise=0.15, factor=0.05, random_state=96)\n",
    "plt.scatter(X2[:,0], X2[:,1], c=y2, cmap=plt.get_cmap(\"cool\"), s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, nauÄite model k-sredina (idealno pretpostavljajuÄ‡i $K=2$) na gornjim podatcima i prikaÅ¾ite dobiveno grupiranje (prouÄite funkciju [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter), posebice argument `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaÅ¡ kÃ´d ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Å to se dogodilo? Koja je pretpostavka algoritma k-sredina ovdje naruÅ¡ena?  \n",
    "**Q:** Å to biste morali osigurati kako bi algoritam pronaÅ¡ao ispravne grupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e)  \n",
    "ZavrÅ¡no, isprobat Ä‡emo algoritam na sljedeÄ‡em umjetno stvorenom skupu podataka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X31, y31 = make_blobs(n_samples=1000, n_features=2, centers=[[0, 0]], cluster_std=[0.2], random_state=69)\n",
    "X32, y32 = make_blobs(n_samples=50, n_features=2, centers=[[0.7, 0.5]], cluster_std=[0.15], random_state=69)\n",
    "X33, y33 = make_blobs(n_samples=600, n_features=2, centers=[[0.8, -0.4]], cluster_std=[0.2], random_state=69)\n",
    "plt.scatter(X31[:,0], X31[:,1], c=\"#00FFFF\", s=20)\n",
    "plt.scatter(X32[:,0], X32[:,1], c=\"#F400F4\", s=20)\n",
    "plt.scatter(X33[:,0], X33[:,1], c=\"#8975FF\", s=20)\n",
    "\n",
    "# Just join all the groups in a single X.\n",
    "X3 = np.vstack([X31, X32, X33])\n",
    "y3 = np.hstack([y31, y32, y33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponovno, nauÄite model k-sredina (ovaj put idealno pretpostavljajuÄ‡i $K=3$) na gornjim podatcima i prikaÅ¾ite dobiveno grupiranje (prouÄite funkciju [`scatter`](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter), posebice argument `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaÅ¡ kÃ´d ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Å to se dogodilo? Koja je pretpostavka algoritma k-sredina ovdje naruÅ¡ena?  \n",
    "**Q:** Å to biste morali osigurati kako bi algoritam pronaÅ¡ao ispravne grupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f)  \n",
    "Sada kada ste se upoznali s ograniÄenjima algoritma k-sredina, isprobat Ä‡ete grupiranje modelom mjeÅ¡avine Gaussa (*Gaussian Mixture Models; GMM*), koji je generalizacija algoritma k-sredina (odnosno, algoritam k-sredina specijalizacija je GMM-a). Implementacija ovog modela dostupna je u [`mixture.GaussianMixture`](http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html). Isprobajte ovaj model (s istim pretpostavkama o broju grupa) na podacima iz podzadataka (c)-(e). Ne morate mijenjati nikakve hiperparametre ni postavke osim broja komponenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VaÅ¡ kÃ´d ovdje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (g)  \n",
    "Kako vrednovati toÄnost modela grupiranja ako imamo stvarne oznake svih primjera (a u naÅ¡em sluÄaju imamo, jer smo mi ti koji smo generirali podatke)? ÄŒesto koriÅ¡tena mjera jest **Randov indeks** koji je zapravo pandan toÄnosti u zadatcima klasifikacije. Implementirajte funkciju `rand_index_score(y_gold, y_predict)` koja ga raÄuna. Funkcija prima dva argumenta: listu stvarnih grupa kojima primjeri pripadaju (`y_gold`) i listu predviÄ‘enih grupa (`y_predict`). Dobro Ä‡e vam doÄ‡i funkcija [`itertools.combinations`](https://docs.python.org/2/library/itertools.html#itertools.combinations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def rand_index_score(y_gold, y_predict):\n",
    "    \n",
    "    # VaÅ¡ kÃ´d ovdje\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** ZaÅ¡to je Randov indeks pandan toÄnosti u klasifikacijskim problemima?  \n",
    "**Q:** Koji su glavni problemi ove metrike?   \n",
    "**Q:** Kako vrednovati kvalitetu grupiranja ako nenamo stvarne oznake primjera? Je li to uopÄ‡e moguÄ‡e?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
