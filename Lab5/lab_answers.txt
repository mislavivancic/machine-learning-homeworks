############### 1 ###############
(a)
Q: Koju zajedniÄku vjerojatnosnu razdiobu ova mreÅ¾a modelira?
 Kako tu informaciju oÄitati iz mreÅ¾e?

A: ZajedniÄka vjerojatnosna razdioba:
p(c,s,r,w) = p(c)*p(s|c)*p(r|c)*p(w|s,r)
Graf se crta tako da bridovi idu iz varijable koja uvjetuje prema varijabli koja je uvjetovana.
Dakle u p(s|c) brid ide iz c u s.

Q: U zadatku koristimo egzaktno zakljuÄivanje. Kako ono radi?

A: Egzaktno zakljuÄivanje koristi bayesovo pravilo. Dakle gledamo primjerice
p(s=1|w=1) = p(s=1,w=1)/p(w=1). Sada je potrebno marginalizirati brojnik i nazivnik.
Dakle brojnik je suma po svim c,r => p(c)*p(s=1|c)*p(r|c)*p(w=1|s=1,r),
a nazivnik je suma po svim c,s,r => p(c)*p(s|c)*p(r|c)*p(w=1|s,r),


Q: Koja je razlika izmeÄ‘u posteriornog upita i MAP-upita?
A: MAP raÄuna Xq =  argmax[Xq]suma po Xn od p(Xq,Xo,Xn) 
MAP-upiti â€“ najvjerojatnija vrijednost varijabli upita.

A posteriorni upit raÄuna p(Xq|Xo) = (suma po Xn od p(Xq,Xo,Xn))/(suma po Xn,Xq od p(Xq,Xo,Xn))
Posteriorni upit je izraÄun uvjetne vjerojatnosti.



Q: ZaÅ¡to je vjerojatnost ğ‘ƒ(ğ‘=1) drugaÄija od ğ‘ƒ(ğ‘=1|ğ‘ =1,ğ‘Ÿ=1) 
ako znamo da Ävorovi ğ‘† i ğ‘… nisu roditelji Ävora ğ¶? 
A: Pa logiÄki gledano ako znamo da je upaljena prskalica i da je padala kiÅ¡a 
to nam donosi neku novu informaciju o vjerojatnosti da je oblaÄno. 


(b)
Q: Kako biste svojim rijeÄima opisali ovaj fenomen, koristeÄ‡i se ovim primjerom?

A: Dakle, kada promatramo ğ‘ƒ(s=1|w=1)=0.4298 i ğ‘ƒ(r=1|w=1)=0.7079 imamo te vjerojatnosti, 
no kada osim opaÅ¾ene vjerojatnosti za w  opazimo jednu od r,odnosno s, vjerojatnosti 
postaju manje tj ğ‘ƒ(s=1|r=1,w=1)=0.1945 i ğ‘ƒ(r=1|s=1,w=1)=0.3204. Ono Å¡to se dogaÄ‘a je to
da opaÅ¾anje da pada kiÅ¡a smanjuje vjerojatnost da je trava mokra zbog prskalice. TakoÄ‘er
ako znamo da je prskalica ukljuÄena i da je trava mokra to nam smanjuje vjerojatnost 
da pada kiÅ¡a.


(c)
Q: KoristeÄ‡i BayesianModel.is_active_trail provjerite jesu li varijable oblaÄnosti (ğ¶) 
i mokre trave (ğ‘Š) uvjetno nezavisne. Å to mora vrijediti kako bi te dvije varijable 
bile uvjetno nezavisne? Provjerite koriÅ¡tenjem iste funkcije.

A: 
# Imamo dva lanca preko S i preko R i buduci na da ni jedan nije opaÅ¾en 
# Ävorovi su povezani.
print(model.is_active_trail('C','W')) # True

# Imamo opaÅ¾en S pa je preko tog lanca nepovezano, ali preko drugog je povezano 
# pa nije d separirano
print(model.is_active_trail('C','W', observed='S')) # True

# Ista stvar kao i gore
print(model.is_active_trail('C','W', observed='R')) # True

# U ovom sluÄaju svi putevi (preko S, R) su nepovezani pa su C i W d-separirani
print(model.is_active_trail('C','W',observed=['S', 'R'])) # False



Q: Kako moÅ¾emo na temelju grafa saznati koje dvije varijable su, uz neka opaÅ¾anja,
uvjetno nezavisne?

A: Dakle svi putevi moraju biti d-separirani pa moÅ¾emo reÄ‡i jesu li uvjetno nezavisni
RaÄvanje: x<-z->y  ako je z opaÅ¾en onda su odvojeni(uvjedno nezavisne od z)
Lanac: x->z->y ako je z opaÅ¾en onda su odvojeni(uvjedno nezavisne od z)
Sraz: x->z<-y  ako je z opeÅ¾en onda su povezani (uvjedno zavisni) 


Q: ZaÅ¡to bismo uopÄ‡e htjeli znati koje su varijable u mreÅ¾i uvjetno nezavisne?
A: UvoÄ‘enjem uvjetne nezavisnosti smanjujemo sloÅ¾enost grafa, tj broj bridova 
izmeÄ‘u Ävorova. Samim time manje raÄunamo 




############### 2 ###############
(b)
Q: Na temelju ovog primjera objasnite zaÅ¡to toÄnost nije uvijek prikladna metrika.

A: U sluÄaku kada imamo disbalans klasa, ondosno recimo da imamo 99 primjeraka klase 1 
i 1 primjerak klase 0. I ako napravimo dummy_classifier koji uvijek vraÄ‡a 1. Njegova Ä‡e
toÄnost biti 99%. Å to bi moglo biti bolje od modela kojeg smo stvarno konstruirali.




Q: ZaÅ¡to koristimo F1-mjeru?
Mjera F1 â€“ harmonijska sredina preciznosti i odziva. F1 je otporna na disbalans
klasa. 
Preciznost je broj toÄnih pozitivnih/(broj svih primjera klasificiranih kao toÄni)
Odziv je broj toÄnih pozitivnih/(broj svih zapravo pozitivnih klasificiranih)
U principu daje bolji uvid u kvalitetu modela u odnosu na ostale mjere.


(c)
Q: ZaÅ¡to "obiÄna" unakrsna provjera nije dovoljno robusna?

A: Prednost K-struke unakrsne provjere je to Å¡to je svaki primjer iskoriÅ¡ten 
i za uÄenje i za ispitivanje.
Nedostatak je Å¡to modeli nisu meÄ‘usobno nezavisni => visoka varijanca procjene.




Q: Å to je to stratificirana k-struka unakrsna provjera? ZaÅ¡to ju Äesto koristimo? 

A: Prednost koriÅ¡tenja je to Å¡to generira test setove takve da imaju podjedanku
distribuciju klasa, ili Å¡to je moguÄ‡e bliÅ¾u distribuciju.


(d)
Q: Koja se metrika optimira pri ovoj optimizaciji?

A: Mislim da je TOÄŒNOST, zato Å¡to u dokumentaciji za gridSearch piÅ¡e
da se koristi od estimatora funkcija score, koja je za logistiÄku regresiju
toÄnost. Valda.


Q: Kako biste odredili broj preklopa ğ‘˜? 

A: Ima nekoliko pristupa odabiru broja preklopa.
Bira se takav k za koji je train/test skup podataka dovoljno velik da 
statistiÄki predstavlja ostatak primjera. Odnosno ne Å¾elimo da nam podaci
ovisno o k-podjeli previÅ¡e variraju.

ObiÄno se bira k={5,10}, ali ne mora biti tako hehe.


(e)
Q: Kako biste odabrali koji su hiperparametri generalno najbolji, 
a ne samo u svakoj pojedinaÄnoj unutarnjoj petlji?

A: Kao optimalan model odabrati onaj koji je najÄeÅ¡Ä‡e odabran u k 
vanjskih preklopa



Q: ÄŒemu u konaÄnici odgovara procjena generalizacijske pogreÅ¡ke?

A: Ako se misli na to kako dobiti pogreÅ¡ku? to MoÅ¾e biti 1- accuracy recimo.
A ne znam zapravo jebemti.


(f)
Q: Koju hipotezu ğ»0 i alternativnu hipotezu ğ»1 testiramo ovim testom?

A: H0 hipoteza je da su toÄnosti iste.
   H1 hipoteza je da su toÄnosti razliÄite.


Q: Koja pretpostavka na vjerojatnosnu razdiobu primjera je napravljena u 
gornjem testu? Je li ona opravdana?
A: MoÅ¾da da su podaci zadani sa istom distribucijom?!


Q: Koji je model u konaÄnici bolji i je li ta prednost znaÄajna uz ğ›¼=0.05?

A: Mogli bi reÄ‡i da je model 2 bolji u zadnjem sluÄaju sa 50 foldova. 
Razlog tome je Å¡to je p_value jako mali. 
Napomena: Ako je pvalue veÄ‡i od recimo 0.05 ili 0.1 ne moÅ¾emo opovrgnuti H0.
Ako je pvalue manji od tih vrijednosti onda moÅ¾emo opovrgnuti H0. 





############### 3 ###############
(a)
Q: Koju biste vrijednost hiperparametra ğ¾ izabrali na temelju ovog grafa? 
ZaÅ¡to? Je li taj odabir optimalan? Kako to znate?

A: K=2. To je mjesto koljena, odnosno gdje fukcija krene blaÅ¾e padati. Ono Å¡to se 
dogodilo u tom trenutku je vjerojatno da smo naÅ¡li prirodnu podjelu, pa daljnje
dijeljenje nema prevelikog utjecaja. 


Q: Je li ova metoda robusna?
A: Problem je kada imamo viÅ¡e tih prirodnih grupiranja, tada Ä‡e funkcija imati
viÅ¡e koljena. TakoÄ‘er, ako su K-srediÅ¡ta sluÄajno uzeta onda je potrebno
raditi viÅ¡e takvih mjerenja za svaki K i uzeti srednju vrijednost.



Q: MoÅ¾emo li izabrati onaj ğ¾ koji minimizira pogreÅ¡ku ğ½? Objasnite.

A: Ne moÅ¾emo, zato Å¡to takav model ima K koji je jednak broju primjera, tj 
svaki model je u svojoj grupi, pa je J = 0.


(b)
Vrijednost a(i) je prosjeÄna udaljenost primjera x(i) do svih drugih primjera 
iz iste grupe.
b(i) Ä‡e biti prosjeÄna udaljenost primjera x(i) do primjera 
najbliÅ¾e susjedne grupe.
Ako je s(i) = 1, to znaÄi da je primjer jako udaljen od primjera iz susjedne 
grupe, obrnuto ako je s(i)=-1 to znaÄi da je primjer jako loÅ¡e grupiran jer 
je bliÅ¾i primjerima iz druge grupe nego iz svoje grupe. 

Q: Kako biste se gledajuÄ‡i ove slike odluÄili za ğ¾?

A: Najbolje je uzeti K za koji je S najveÄ‡i, s tim da za svaku grupu mora
vrijediti da je je iznad prosjeÄne vrijednosti S, takoÄ‘er poÅ¾eljno je da 
su vrijednosti S za pojedinu grupu Å¡to sliÄnije.


Q: Koji su problemi ovog pristupa?

A: 

(c)
Q: Å to se dogodilo? Koja je pretpostavka algoritma k-sredina ovdje naruÅ¡ena?
A: 


Q: Å to biste morali osigurati kako bi algoritam pronaÅ¡ao ispravne grupe?
A: 


(d)
Q: Å to se dogodilo? Koja je pretpostavka algoritma k-sredina ovdje naruÅ¡ena?
A: 


Q: Å to biste morali osigurati kako bi algoritam pronaÅ¡ao ispravne grupe?
A:


(e)
Q: Å to se dogodilo? Koja je pretpostavka algoritma k-sredina ovdje naruÅ¡ena?
A:

Q: Å to biste morali osigurati kako bi algoritam pronaÅ¡ao ispravne grupe?
A: 



(g)
Q: ZaÅ¡to je Randov indeks pandan toÄnosti u klasifikacijskim problemima?

A: Mi sa Randovim indeksom gledamo sve parove. IzmeÄ‘u njih gledamo jesu
li ta dva para zavrÅ¡ila u istoj grupi i ako je ta grupa ispravna. Ako jesu 
onda oni predstavljaju True Positive. InaÄe ako oba primjera nisu zavrÅ¡ila 
u istoj grupi, a ni nisu trebali zavrÅ¡it u istoj grupi to nam predstavlja
True Negative.
JoÅ¡ jednom:
"a" predstavlja broj jednako oznaÄenih parova u istim grupama, 
a "b" je broj razliÄito oznaÄenih parova u razliÄitim grupama.


Q: Koji su glavni problemi ove metrike?
A: Pa problem je kad nemamo ni jedan oznaÄen primjer. Odnosno kad ne znamo
jesu grupe u kojima su zavrÅ¾ili primjeri toÄne ili nisu. U tim sluÄajevima
moÅ¾emo neki manji uzorak ruÄno oznaÄiti te tada raÄunati randov indeks.


Q: Kako vrednovati kvalitetu grupiranja ako nenamo stvarne oznake primjera? 
Je li to uopÄ‡e moguÄ‡e?
A: Mislim da je odgovor ovo iznad. ZnaÄi da ruÄno oznaÄimo neki manji uzorak,
pa da po uzoru na to raÄunamo Randov index.hr
